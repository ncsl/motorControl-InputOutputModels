{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "import scipy, scipy.io\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "## sklearn imports\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        elif isinstance(elem,np.ndarray):\n",
    "            dict[strg] = _tolist(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _tolist(ndarray):\n",
    "    '''\n",
    "    A recursive function which constructs lists from cellarrays \n",
    "    (which are loaded as numpy ndarrays), recursing into the elements\n",
    "    if they contain matobjects.\n",
    "    '''\n",
    "    elem_list = []            \n",
    "    for sub_elem in ndarray:\n",
    "        if isinstance(sub_elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            elem_list.append(_todict(sub_elem))\n",
    "        elif isinstance(sub_elem,np.ndarray):\n",
    "            elem_list.append(_tolist(sub_elem))\n",
    "        else:\n",
    "            elem_list.append(sub_elem)\n",
    "    return elem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFile = '../Monkey X/clusters/pearsonRSpectralClustered_allconditions'\n",
    "data = loadmat(dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices for each neuron:  [3 3 3 1 3 3 3 3 3 1 3 3 3 3 3 1 4 3 3 2 3 3 2 3 3 3 3 3 3 1 3 1 3 3 4 4 3\n",
      " 3 3 3 3 1 3 3 2 3 3 3 1 3 3 2 2 3 3 3 3 2 3 1 3 3 3 3 3 3 3 3 1 3 2 3 3 1\n",
      " 3 3 3 1 3 3 1 3 1 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 1 2 3 3 3 3\n",
      " 3 3 1 3 3 2 3 2 3 2 3 3 3 3 2 3 1 2 3 2 3 3 3 3 3 1 3 4 3 3 3 3 3 3 3 3 3\n",
      " 1 3 3 3 3 2 3 3 4 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "indiceFile = '../Monkey X/clusters/cindices'\n",
    "indices = loadmat(indiceFile)\n",
    "indices = indices['clusters']\n",
    "print \"The indices for each neuron: \", indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sig001a', 'sig001b', 'sig001c', 'sig003a', 'sig003b', 'sig003c', 'sig004a', 'sig004b', 'sig004c', 'sig004d', 'sig005a', 'sig005b', 'sig005c', 'sig005d', 'sig006a', 'sig006b', 'sig006c', 'sig007a', 'sig007b', 'sig007c', 'sig007d', 'sig008a', 'sig008b', 'sig008c', 'sig008d', 'sig009a', 'sig009b', 'sig010a', 'sig010b', 'sig011a', 'sig011b', 'sig012a', 'sig012b', 'sig014a', 'sig014b', 'sig014c', 'sig014d', 'sig015a', 'sig015b', 'sig020a', 'sig021a', 'sig021b', 'sig022a', 'sig022b', 'sig025a', 'sig027a', 'sig028a', 'sig033a', 'sig033b', 'sig033c', 'sig033d', 'sig034a', 'sig034b', 'sig034c', 'sig034d', 'sig035a', 'sig035b', 'sig036a', 'sig036b', 'sig036c', 'sig036d', 'sig037a', 'sig037b', 'sig037c', 'sig038a', 'sig038b', 'sig038c', 'sig038d', 'sig039a', 'sig039b', 'sig039c', 'sig040a', 'sig040b', 'sig041a', 'sig041b', 'sig041c', 'sig041d', 'sig042a', 'sig042b', 'sig043a', 'sig043b', 'sig046a', 'sig046b', 'sig046c', 'sig047a', 'sig047b', 'sig047c', 'sig047d', 'sig051a', 'sig052a', 'sig052b', 'sig054a', 'sig056a', 'sig058a', 'sig060a', 'sig060b', 'sig060c', 'sig067a', 'sig070a', 'sig070b', 'sig071a', 'sig071b', 'sig071c', 'sig074a', 'sig074b', 'sig075a', 'sig078a', 'sig078b', 'sig081a', 'sig081b', 'sig081c', 'sig083a', 'sig089a', 'sig089b', 'sig090a', 'sig091a', 'sig092a', 'sig092b', 'sig094a', 'sig094b', 'sig094c', 'sig095a', 'sig096a', 'sig096b', 'sig096c', 'sig096d', 'sig097a', 'sig097b', 'sig097c', 'sig098a', 'sig098b', 'sig099a', 'sig099b', 'sig102a', 'sig104a', 'sig104b', 'sig105a', 'sig105b', 'sig105c', 'sig106a', 'sig107a', 'sig110a', 'sig111a', 'sig111b', 'sig111c', 'sig112a', 'sig113a', 'sig113b', 'sig115a', 'sig115b', 'sig116a', 'sig117a', 'sig117b', 'sig117c', 'sig118a', 'sig118b', 'sig118c', 'sig120a', 'sig120b', 'sig120c', 'sig121a', 'sig121b', 'sig123a', 'sig123b', 'sig123c', 'sig124a', 'sig124b']\n"
     ]
    }
   ],
   "source": [
    "# get the neuron names in order\n",
    "binNeuronDir = '../Monkey X/binned neurons 1ms/'\n",
    "fileNames = []\n",
    "for file in os.listdir(binNeuronDir):\n",
    "    fileNames.append(file[0:len(file)-4])\n",
    "print fileNames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 15, 29, 31, 41, 48, 59, 68, 73, 77, 80, 82, 105, 113, 127, 136, 148]\n",
      "['sig003a', 'sig004d', 'sig006b', 'sig011a', 'sig012a', 'sig021b', 'sig033b', 'sig036c', 'sig039a', 'sig041a', 'sig042a', 'sig043b', 'sig046b', 'sig075a', 'sig089b', 'sig097b', 'sig105a', 'sig115a']\n"
     ]
    }
   ],
   "source": [
    "cluster_indices = [i for i,x in enumerate(indices) if x == 1]\n",
    "print cluster_indices\n",
    "\n",
    "cluster_neurons = []\n",
    "for index in cluster_indices: # loop through each index\n",
    "    cluster_neurons.append(fileNames[index])\n",
    "    \n",
    "print cluster_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig003a\n",
      "['trial69', 'trial68', 'trial61', 'trial60', 'trial63', 'trial62', 'trial65', 'trial64', 'trial67', 'trial66', 'trial89', 'trial88', 'trial83', 'trial82', 'trial81', 'trial80', 'trial87', 'trial86', 'trial85', 'trial84', 'trial76', 'trial77', 'trial74', 'trial75', 'trial72', 'trial73', 'trial70', 'trial71', 'trial78', 'trial79', 'trial98', 'trial99', 'trial90', 'trial91', 'trial92', 'trial93', 'trial94', 'trial95', 'trial96', 'trial97', 'trial112', 'trial113', 'trial111', 'trial116', 'trial117', 'trial114', 'trial115', 'trial11', 'trial12', 'trial13', 'trial14', 'trial15', 'trial16', 'trial17', 'trial18', 'trial19', 'trial109', 'trial108', 'trial105', 'trial104', 'trial107', 'trial106', 'trial101', 'trial100', 'trial103', 'trial102', 'trial29', 'trial28', 'trial25', 'trial24', 'trial27', 'trial26', 'trial21', 'trial20', 'trial23', 'trial22', 'trial49', 'trial48', 'trial47', 'trial46', 'trial45', 'trial43', 'trial42', 'trial41', 'trial40', 'trial38', 'trial39', 'trial32', 'trial33', 'trial30', 'trial31', 'trial36', 'trial37', 'trial34', 'trial35', 'trial58', 'trial59', 'trial54', 'trial55', 'trial56', 'trial57', 'trial50', 'trial51', 'trial52', 'trial53', 'trial8', 'trial9', 'trial2', 'trial3', 'trial1', 'trial6', 'trial7', 'trial4', 'trial5']\n"
     ]
    }
   ],
   "source": [
    "for neuron in cluster_neurons:\n",
    "    print neuron\n",
    "    data = loadmat(os.path.join(binNeuronDir, neuron))\n",
    "    binned_neuron = data['binned_neuron']\n",
    "    push = binned_neuron['push']\n",
    "    trials = push.keys()\n",
    "    \n",
    "    # just look at 1 trial\n",
    "    extrial = push['trial1']\n",
    "    \n",
    "    print extrial.keys()\n",
    "    print push.keys()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['push', 'pull', 'sphere', 'mallet']\n"
     ]
    }
   ],
   "source": [
    "print binned_neuron.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
